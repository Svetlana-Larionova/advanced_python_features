"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ Python
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å, –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
"""

import asyncio
import aiohttp
import requests
import concurrent.futures
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import time
import logging
from dataclasses import dataclass

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class BatchConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    batch_size: int = 5
    max_workers: int = 3
    timeout: int = 10


class BaseModel(ABC):

    @abstractmethod
    def download_data(self, categories: List[int]) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        pass

    @abstractmethod
    def transform_to_dict(self, data: Any) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª–æ–≤–∞—Ä—å"""
        pass


class AdvancedWoysaLoader(BaseModel):
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        self.base_url = 'https://analitika.woysa.club/images/panel/json/download/niches.php'
        self.batch_config = BatchConfig()
        logger.info("üöÄ AdvancedWoysaLoader –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def download_data(self, categories: List[int]) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        logger.info(f"üì• –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ {len(categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        results = {}

        for category in categories:
            try:
                url = self._build_url(category)
                response = requests.get(url, timeout=self.batch_config.timeout)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON
                content_type = response.headers.get('content-type', '')
                if 'application/json' in content_type:
                    results[str(category)] = response.json()
                    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è {category}")
                else:
                    # –ï—Å–ª–∏ –Ω–µ JSON, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                    results[str(category)] = {
                        "content_type": content_type,
                        "text_preview": response.text[:100] + "..." if len(response.text) > 100 else response.text,
                        "status_code": response.status_code
                    }
                    logger.info(f"‚ö†Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category}: –ø–æ–ª—É—á–µ–Ω {content_type}")

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
                results[str(category)] = {"error": str(e)}

        return results

    async def download_data_async(self, categories: List[int]) -> Tuple[Dict[str, Any], float]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        logger.info(f"‚ö° –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ {len(categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        start_time = time.time()
        results = {}

        async with aiohttp.ClientSession() as session:
            tasks = []
            for category in categories:
                task = self._download_single_category_async(session, category)
                tasks.append(task)

            category_results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, category in enumerate(categories):
                if isinstance(category_results[i], Exception):
                    results[str(category)] = {"error": str(category_results[i])}
                else:
                    results[str(category)] = category_results[i]

        end_time = time.time()
        return results, end_time - start_time

    async def _download_single_category_async(self, session: aiohttp.ClientSession, category: int) -> Any:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            url = self._build_url(category)
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=self.batch_config.timeout)) as response:

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type
                content_type = response.headers.get('content-type', '')
                if 'application/json' in content_type:
                    data = await response.json()
                    logger.info(f"‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è {category}")
                    return data
                else:
                    # –ï—Å–ª–∏ –Ω–µ JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –æ—Ç–≤–µ—Ç–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    try:
                        text = await response.text()
                    except UnicodeDecodeError:
                        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏, —á–∏—Ç–∞–µ–º –∫–∞–∫ –±–∞–π—Ç—ã
                        bytes_data = await response.read()
                        text = bytes_data.decode('utf-8', errors='replace')

                    return {
                        "content_type": content_type,
                        "text_preview": text[:100] + "..." if len(text) > 100 else text,
                        "status_code": response.status,
                        "url": str(response.url)
                    }

        except Exception as e:
            logger.error(f"‚ùå –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
            return {"error": str(e)}

    def download_data_threaded(self, categories: List[int]) -> Dict[str, Any]:
        """–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        logger.info(f"üéØ –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ {len(categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        results = {}

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.batch_config.max_workers) as executor:
            future_to_category = {
                executor.submit(self._download_single_category_sync, category): category
                for category in categories
            }

            for future in concurrent.futures.as_completed(future_to_category):
                category = future_to_category[future]
                try:
                    results[str(category)] = future.result()
                    logger.info(f"‚úÖ –ü–æ—Ç–æ–∫–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
                    results[str(category)] = {"error": str(e)}

        return results

    def _download_single_category_sync(self, category: int) -> Any:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏"""
        try:
            url = self._build_url(category)
            response = requests.get(url, timeout=self.batch_config.timeout)

            content_type = response.headers.get('content-type', '')
            if 'application/json' in content_type:
                return response.json()
            else:
                return {
                    "content_type": content_type,
                    "text_preview": response.text[:100] + "..." if len(response.text) > 100 else response.text,
                    "status_code": response.status_code
                }

        except Exception as e:
            raise e

    def download_data_batched(self, categories: List[int]) -> Dict[str, Any]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º numpy"""
        logger.info(f"üì¶ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

        if not categories:
            return {}

        # –†–∞–∑–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –ø–∞–∫–µ—Ç—ã
        batches = np.array_split(categories, max(1, len(categories) // self.batch_config.batch_size))
        logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ {len(batches)} –ø–∞–∫–µ—Ç–æ–≤")

        all_results = {}

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.batch_config.max_workers) as executor:
            future_to_batch = {
                executor.submit(self._process_batch, batch): i
                for i, batch in enumerate(batches)
            }

            for future in concurrent.futures.as_completed(future_to_batch):
                batch_num = future_to_batch[future]
                try:
                    batch_results = future.result()
                    all_results.update(batch_results)
                    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –ø–∞–∫–µ—Ç {batch_num + 1}/{len(batches)}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_num}: {e}")

        return all_results

    def _process_batch(self, batch: np.ndarray) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        batch_results = {}

        for category in batch:
            try:
                url = self._build_url(int(category))
                response = requests.get(url, timeout=self.batch_config.timeout)

                content_type = response.headers.get('content-type', '')
                if 'application/json' in content_type:
                    batch_results[str(category)] = response.json()
                else:
                    batch_results[str(category)] = {
                        "content_type": content_type,
                        "text_preview": response.text[:100] + "..." if len(response.text) > 100 else response.text,
                        "status_code": response.status_code
                    }

            except Exception as e:
                batch_results[str(category)] = {"error": str(e)}

        return batch_results

    def transform_to_dict(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å"""
        logger.info("üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª–æ–≤–∞—Ä—å")

        transformed = {
            "categories": {},
            "statistics": {
                "total": len(data),
                "successful": 0,
                "errors": 0,
                "non_json_responses": 0
            }
        }

        for category, category_data in data.items():
            if isinstance(category_data, dict) and "error" in category_data:
                transformed["categories"][category] = {
                    "status": "error",
                    "message": category_data["error"]
                }
                transformed["statistics"]["errors"] += 1
            elif isinstance(category_data, dict) and "content_type" in category_data:
                transformed["categories"][category] = {
                    "status": "non_json",
                    "content_type": category_data.get("content_type"),
                    "status_code": category_data.get("status_code"),
                    "preview": category_data.get("text_preview", "")
                }
                transformed["statistics"]["non_json_responses"] += 1
            else:
                transformed["categories"][category] = {
                    "status": "success",
                    "data": category_data,
                    "items_count": len(category_data) if isinstance(category_data, list) else 1
                }
                transformed["statistics"]["successful"] += 1

        return transformed

    def _build_url(self, category: int) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        params = {
            "id_cat": category,
            "skip": 0,
            "pricemin": 0,
            "price_max": 1060225
        }
        query_string = "&".join(f"{k}={v}" for k, v in params.items())
        return f"{self.base_url}?{query_string}"


# –ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
class PerformanceBenchmark:
    @staticmethod
    def measure_time(func, *args, **kwargs) -> Tuple[Any, float]:
        """–ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏"""
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        return result, end_time - start_time


async def main():
    print("=" * 60)
    print("üöÄ –ü–†–û–î–í–ò–ù–£–¢–´–ô PYTHON: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ")
    print("=" * 60)

    loader = AdvancedWoysaLoader()
    benchmark = PerformanceBenchmark()

    # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–µ–Ω—å—à–µ –¥–ª—è —Ç–µ—Å—Ç–∞)
    test_categories = [100, 200, 300, 400, 500]

    print(f"üìã –¢–µ—Å—Ç–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {test_categories}")
    print()

    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    print("1. üîÑ –°–ò–ù–•–†–û–ù–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê:")
    sync_data, sync_time = benchmark.measure_time(loader.download_data, test_categories)
    print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {sync_time:.2f} —Å–µ–∫")
    print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(sync_data)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    print("\n2. üéØ –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê:")
    threaded_data, threaded_time = benchmark.measure_time(
        loader.download_data_threaded, test_categories
    )
    print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {threaded_time:.2f} —Å–µ–∫")
    print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(threaded_data)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n3. üì¶ –ü–ê–ö–ï–¢–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê:")
    batched_data, batched_time = benchmark.measure_time(
        loader.download_data_batched, test_categories
    )
    print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {batched_time:.2f} —Å–µ–∫")
    print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(batched_data)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    print("\n4. ‚ö° –ê–°–ò–ù–•–†–û–ù–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê:")
    async_data, async_time = await loader.download_data_async(test_categories)
    print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {async_time:.2f} —Å–µ–∫")
    print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(async_data)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print("\n5. üîÑ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•:")
    transformed = loader.transform_to_dict(async_data)
    print(f"   üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {transformed['statistics']}")

    print("\n" + "=" * 60)
    print("üéØ –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
    print(f"   –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è:    {sync_time:.2f} —Å–µ–∫")
    print(f"   –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è: {threaded_time:.2f} —Å–µ–∫")
    print(f"   –ü–∞–∫–µ—Ç–Ω–∞—è:      {batched_time:.2f} —Å–µ–∫")
    print(f"   –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è:   {async_time:.2f} —Å–µ–∫")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤
    print("\nüìã –ü–†–ò–ú–ï–†–´ –û–¢–í–ï–¢–û–í:")
    for category in test_categories[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        data = async_data.get(str(category), {})
        if isinstance(data, dict) and "error" in data:
            status = "‚ùå –û—à–∏–±–∫–∞"
        elif isinstance(data, dict) and "content_type" in data:
            status = "‚ö†Ô∏è HTML"
        else:
            status = "‚úÖ JSON"
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category}: {status}")
        if "content_type" in data:
            print(f"      Content-Type: {data.get('content_type')}")
            print(f"      Preview: {data.get('text_preview')}")
        if "error" in data:
            print(f"      Error: {data.get('error')}")


if __name__ == "__main__":
    asyncio.run(main())